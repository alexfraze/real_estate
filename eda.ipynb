{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'statsmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-087ee58558eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinregress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexponential_smoothing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mETSModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'statsmodels'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.exponential_smoothing.ets import ETSModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#using single family home prices historical dataset (zillow has a few other options as well to try including w/ condos, Xbedrooms, etc.)\n",
    "sfh_prices = pd.read_csv(\"/Users/afrazier/Documents/personal/real_estate/data/single_family_historical.csv\")\n",
    "print(sfh_prices.index.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-processing, filter out zipcodes without significant populations\n",
    "twenty_ten_census_zip_populations = pd.read_csv(\"data/population_by_zip_2010.csv\")\n",
    "zip_populations = twenty_ten_census_zip_populations.groupby('zipcode')['population'].sum().reset_index()\n",
    "prices_with_pops = sfh_prices.merge(zip_populations, left_on=\"RegionName\", right_on=\"zipcode\")\n",
    "print(prices_with_pops.index.size)\n",
    "#filter to zips with atleast 25K people living there\n",
    "min_population = 25000\n",
    "prices_with_pops = prices_with_pops[prices_with_pops.population>min_population]\n",
    "print(prices_with_pops.index.size)\n",
    "sfh_prices = prices_with_pops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#melt the date,price into multiple rows instead of one wide table\n",
    "date_cols = [x for x in sfh_prices.columns if sfh_prices[x].dtype=='float64']\n",
    "melted_prices = pd.melt(sfh_prices, id_vars=['RegionID', 'SizeRank', 'RegionName', 'RegionType', 'StateName','State', 'City', 'Metro', 'CountyName'], value_vars=date_cols)\n",
    "melted_prices = melted_prices.rename(columns = {\"variable\": \"date\", \"value\": \"price\"})\n",
    "melted_prices.date = pd.to_datetime(melted_prices.date)\n",
    "# remove years/zips with null prices -> 693977/5044869 (~14%) null prices \n",
    "melted_prices = melted_prices[~(melted_prices.price.isnull())]\n",
    "#calculate monthly changes in price\n",
    "melted_prices['monthly_price_change'] = melted_prices.sort_values([\"RegionName\", \"date\"])['price'].diff()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add in the year distnace from the last date so we can perform regression on the price\n",
    "max_date = melted_prices.date.max()\n",
    "melted_prices['months_difference'] = (melted_prices.date-max_date)/(np.timedelta64(1, 'M'))\n",
    "\n",
    "#filter to only datapoints from the last 5 years (12*5=16)\n",
    "#can try other values here as it might be nice to include the 2008 crash as well\n",
    "melted_prices = melted_prices[melted_prices.months_difference>-60]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate slope, std, and number datapoints\n",
    "zipcode_slopes = melted_prices.sort_values([\"RegionName\", \"date\"]).groupby(\"RegionName\").apply(\n",
    "            lambda x: linregress(x.months_difference, x['price'])[0]).round()\n",
    "zipcode_slopes.name = \"monthly_price_slope\"\n",
    "zipcode_price_change_stds = melted_prices.groupby(\"RegionName\")['monthly_price_change'].std().round()\n",
    "zipcode_price_change_stds.name = \"monthly_price_change_std\"\n",
    "zipcode_datapoints = melted_prices.groupby(\"RegionName\")['price'].size()\n",
    "zipcode_datapoints.name = \"total_data_points\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_year_slope_and_stds = pd.concat([zipcode_slopes, zipcode_price_change_stds, zipcode_datapoints], axis=1)\n",
    "#lets filter to zipcodes with atleast 3 years of data?\n",
    "ten_year_slope_and_stds =  ten_year_slope_and_stds[ten_year_slope_and_stds.total_data_points>=36]\n",
    "\n",
    "ten_year_slope_and_stds.plot.scatter(x=\"monthly_price_slope\", y=\"monthly_price_change_std\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_year_slope_and_stds['sharpe_ratios'] =  ten_year_slope_and_stds['monthly_price_slope']/ten_year_slope_and_stds['monthly_price_change_std']\n",
    "\n",
    "\n",
    "#Lets Just look at zip codes with >2k a month\n",
    "growth = ten_year_slope_and_stds[ten_year_slope_and_stds.monthly_price_slope>10000]\n",
    "growth.sort_values('sharpe_ratios', ascending=False)[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interesting zipcodes \n",
    "# with slower appreciation but low std (risk)\n",
    "#1. 84532 - Moab, UT (arches?!)\n",
    "#2. 84032 - Wasatch County, Utah\n",
    "#3. 98632 - Longview, WA 98632\n",
    "\n",
    "\n",
    "#with larger appreciaion\n",
    "#and still relatively low risk\n",
    "#1. 91108 - Pasadena, CA  -> no houses in this specific zip?\n",
    "#2. 90211 - Beverly Hills, CA 90211\n",
    "\n",
    "melted_prices[melted_prices.RegionName==91108][['date', 'price']].set_index(\"date\").plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#why no austin, nash in these lists? which filter is removing them?\n",
    "\n",
    "\n",
    "#east side has 4K appreciation with lowish std. -> 0.57 sharpe\n",
    "\n",
    "# 78702, east side austin\n",
    "ten_year_slope_and_stds[ten_year_slope_and_stds.index==78702]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "price_plot = melted_prices[melted_prices.RegionName==78702][['date', 'price']].set_index(\"date\").plot(ax=ax, label=\"actual\")\n",
    "linear_fit_x = price_plot.lines[0].get_xdata()\n",
    "linear_fit_y = np.arange(400000,400000+4030.0*len(linear_fit_x), 4030)\n",
    "# linear_fit_x = [x.to_timestamp() for x in linear_fit_x]\n",
    "ax.plot(linear_fit_x, linear_fit_y, label=\"linear_fit\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#austin has much higher appreciation in the last few years. can we build a slightly better forecast than linear?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#requirements -> good sharpe ratio of risk to return. ideally >0.5\n",
    "\n",
    "# forecasted annual property value increase of >20K\n",
    "#have a basic linear model but might want to look into other things here\n",
    "\n",
    "\n",
    "#things to add\n",
    "# population is growing at decent rate\n",
    "# major school, grocery store, and hospital within 10-20 miles of home\n",
    "# Average salary/income shows a positive trend for this place too! \n",
    "\n",
    "\n",
    "# rental yield is strong. ie, i can make 1% of house cost in rent each year? (check vs BRRRRR book rule)\n",
    "# or I can make X dollars in rent each year. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1ee38ef4a5a9feb55287fd749643f13d043cb0a7addaab2a9c224cbe137c0062"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
